\section{Introduction}

Web applications have become mainstream in the last decade. Their
vulnerabilities pose a great risk because they can easily be exploited
by malicious attackers through the Internet.
Web Application Firewalls (WAF) can be placed in front of these
applications to minimize the risk of attacks \cite{torranoGimenez2015study}.

According to the detection method, a WAF can be either \textit{misuse-based},
when in looks for known attack signatures,
or \textit{anomaly-based}, when it aims to differentiate between normal and
anomalous HTTP requests, where the anomalies can include malicious attacks
\cite{torranoGimenez2015study}.
In order to accomplish this differentiation task, the WAF needs to recognize
characteristics about the individual HTTP requests.
This kind of WAF has two phases, namely training and detection.
During the training phase, it extracts models from observed normal requests.
During the detection phase, it compares the incoming requests to these models
and flags them as anomalous if they deviate significantly from normal
requests previously seen.
A great strength of this approach lies with the fact that the WAF only needs
to be retrained if there are changes in the applications it protects
and not because of the appearance of new attacks \cite{kruegel2003anomaly}.

For the anomaly detection process of the WAF, one possible strategy is to
face it as a classification problem with a single positive class,
denominated One Class Classification (OCC) problem \cite{khan2014one}.
This way the normal HTTP requests belong to this single positive class and
all the anomalies will be categorized as not belonging to this class.
This OCC approach has the advantage of not needing labeled anomalous data
for training, only normal requests are required.
One methodology to solve OCC problems is to employ tools from the area of
Machine Learning, one of those being the \textit{One-Class} SVM, which has
been used with great success for this kind of problems \cite{khan2014one}.
The characteristics of HTTP requests need to be expressed as numeric
feature vectors in order to be used by this classifier.

In this article, we present a WAF based on anomaly detection that uses
features selected with expert knowledge about HTTP requests and also uses
\textit{One-Class} SVM classifier to detect anomalous requests.
In Section \ref{chap:related_works} we present related works, in Section
\ref{chap:proposal} we describe our proposed WAF, Section \ref{chap:results}
contains our test results and we finish this paper with some conclusions and
ideas for future work in Section \ref{chap:conclusions}.


\section{Related works}
\label{chap:related_works}

In \cite{kruegel2003anomaly} and \cite{kruegel2005multi} the authors use
expert knowledge about the structure of HTTP requests in their anomaly
detection system.
They describe how the query string of an HTTP request consists of an ordered
list of $n$ pairs of parameters and their corresponding values and how
they use statistical methods to build anomaly models of the values for
each of the parameters. Some of the models they use are the length of the
values, their character distribution, structural inference, parameter
presence, among others.
For example, one of their models describes the string length of the different
values that appear for the parameter \textit{username} in the URL
\textit{/login}.
The approach of these authors differs from ours in that they use statistical
methods to detect anomalous requests while we employ \textit{One-Class} SVM.
Similar HTTP features and statistical detection methods are used in
\cite{torranoGimenez2015study}.

The \textit{One-Class} SVM has been used successfully in many areas,
including text classification, face recognition, spam detection, anomaly
detection, among others \cite{khan2014one}.
In \cite{tran2004one}, network traffic statistics are computed with
\textit{tcpstat} and fed to a \textit{One-Class} SVM to detect anomalous
network packets.
In \cite{perdisci2006using}, byte \textit{n}-grams are extracted of the
payload of network packets and passed to an ensemble of \textit{One-Class}
SVMs to detect mimicry attacks.
The authors in \cite{parhizkar2015oc} extract a fixed number of features
from HTTP requests and use an ensemble of \textit{One-Class} SVMs to
detect attacks in web traffic. This last paper also uses the same data
sets we employ, and later we compare our results with theirs.
It is worth noting that the three cited works use a fixed number of
features, while in our WAF this number depends on the quantity of parameters
in the training data.


\section{Proposal}
\label{chap:proposal}

In this section, we describe the four main parts that make up our WAF,
namely a routing step, a data preprocessing step, a classification step
and lastly a response step.
Our implementation was done in the programming language \textit{Python}
using the Machine Learning library \textit{scikit-learn} and the code
is accessible in our online repository under \TheRepoUrl.


\subsection{Routing step}

Since requests to the same URL show a greater similarity to each other
than to requests to other URLs, our routing step groups the incoming
requests by URL and HTTP method. This way during the training phase the
anomaly models can be built independently for each group, resulting in a
more precise description of the normal requests within each group.
Consequently, during the detection phase there are more accurate models of
normal requests available, which help to identify requests that are
anomalous within their corresponding groups, even though they would be
considered normal in other groups.


\subsection{Data preprocessing step}

Our data preprocessing step extracts a vector of numeric features from
each HTTP request, which is then passed to the classification step.
We use feature extraction methods that yield a total of 10 numeric features.
Four of our features indicate total length, number of digits, number of
letters and number of non-alphanumerical characters. We based these
on \cite{kruegel2003anomaly} and \cite{nguyen2011application}, adding
some own extensions.
Another five features, also based on \cite{kruegel2003anomaly}, represent
the bins of a method called character distribution.
Our last feature represents the entropy according to Shannon
\cite{encyMathEntropy}, an idea taken from \cite{nguyen2011application}.

Our feature extraction methods are applied to the whole request,
including HTTP method, URL, query string, headers, and body.
Additionally, we employ the previously mentioned approach used in
\cite{kruegel2003anomaly} and apply our extraction methods on each of the
parameter values in the query string. We extend this approach to also
analyze the parameter values in the body of the requests if there are any.

The obtained feature vector that represents a request will have
$m \times (1 + n)$ features.
Here $m$ is the number of features returned by our feature extraction
methods for each value.
The $1$ represents the whole request and $n$ is the number of parameters
that are present in the query string and body.
Its important to note that $n$ might be different for each group of URL
and HTTP method.
During the training phase, all the different parameters from a group of
requests are listed and given a fixed order for building the feature vector.
This way, during the detection phase our WAF extracts the features of the
values whose parameters have been seen in the training phase, assuring that
their position within the vector is preserved.
For example, if during training our WAF gets POST request which all have
only the parameters \textit{username} and \textit{password} in its body,
then $m = 10$ and $n = 2$, resulting in each request being represented by
a vector of 30 features.

We are aware that our analysis of parameter values during the detection
phase is only applied to parameters observed in training.
This gives way to the risk of an intruder including an attack inside the
value of a previously unseen parameter.
But since our feature extraction methods are also applied to the whole
request, these attacks can still be detected and do not simply bypass
our WAF.


\subsection{Classification step}

During the training phase, our WAF scales and normalizes the numeric feature
vectors produced by the previous step and trains one \textit{One-Class} SVM
classifier for each group of URL and HTTP method.
In this high dimensional vector space, the classifier tries to find boundaries
to the regions in which the feature vectors of normal request reside,
drawing these borders as tight as possible to exclude future vectors of
anomalous requests, but loose enough to still include future normal requests
not seen in the training phase \cite{perdisci2006using}.
This way the WAF obtains a model, a trained classifier, that generalizes
the characteristics of normal HTTP requests within each group.

During the detection phase, the incoming requests are routed to their
corresponding group, the feature extraction methods are applied and the
trained classifier for that group checks if this new feature vector
falls inside the established boundaries, marking it as normal if it does.
All other requests will be denoted as anomalous.

The \textit{One-Class} SVM takes a few parameters that influence its
behavior.
One of these parameters, denominated $nu$ or $\nu$, is used to set an upper
bound to the fraction of training requests that may fall outside of the
established boundaries. This gives the classifier some flexibility when
drawing the borders in order to achieve higher generalization capabilities
and also achieves robustness in case of some anomalies in the training
data \cite{scholkopf2001estimating}.
Sometimes it can be difficult to find boundaries in the given vector space,
so the classifier can use a so called kernel function to simulate a
higher dimensionality in which it is easier to draw the separating borders.
We tested three kernels, namely the linear, the polynomial and the
\textit{Radial Basis Function} (RBF) kernel. We obtained the best
classification results with the last one.
The RBF kernel also has a parameter called $gamma$ or $\gamma$ that
influences the shape of the boundaries \cite{tran2004one}.


\subsection{Response step}

Our WAF can be configured to respond in different ways to the classification
results. If a request is considered normal, it is forwarded to its intended
destination. Otherwise, the WAF logs the result and optionally can also
block that request, preventing possible attacks from reaching the applications.
Our implementation could be extended, for example, to send alarms about
anomalies to the people responsible for the system.


\section{Experiments and results}
\label{chap:results}

For the quantitative evaluation of the performance of our WAF, we used the
public data sets CSIC 2010 \cite{csic2010dataset} and CSIC TORPEDA 2012
\cite{torpeda2012dataset}, which contain labeled HTTP requests to an
e-commerce web application.
Given that our WAF groups the requests by URL and HTTP method, we grouped
the requests from both data sets by these criteria and selected those
groups that had more than 100 samples of each of the two categories,
normal and anomalous.
This left us with 18 groups, totaling 40,130 normal and 42,444 anomalous
HTTP requests.


\subsection{Detection effectiveness test}

In a first test, we used the aforementioned data to measure the detection
effectiveness of our WAF.
To demonstrate the added value of analyzing the parameter values, we
tested two different scenarios. Firstly, we applied our feature extraction
methods only to the whole request, obtaining a fixed number of 10 features.
Secondly, we included the analysis of parameter values, yielding different
number of features for each group, as described in the previous section.
Additionally, for the selection of $\nu$ and $\gamma$ for each group,
we tested values in the range $[0.0001: 0.1]$ and chose those that gave
the best result in each group.
Table \ref{tbl:test_1_results} shows average and standard deviation of
true positive rate (TPR), false positive rate (FPR) and $F_{1}$ score
of our results. $F_{1}$ score uses the number of true positives (TP),
false positives (FP) and false negatives (FN), and it is expressed as
$ F_{1} = \frac{2TP}{2TP + FP + FN} $,
where values closer to 1 indicate better results.

\begin{table}[!b]
    \centering
    \caption{Results of detection effectiveness test for all 18 groups}
    \label{tbl:test_1_results}

    \small
    \begin{tabularx}{\linewidth}{|C|c|c|c|c|}
        \hline
        Scenario                     & average TPR   & average FPR   & average $F_{1}$ & best $F_{1}$ \\ \hline
        using only the whole request & $0.91 \pm 0.11$ & $0.31 \pm 0.34$ & $0.82 \pm 0.18$ & $1.00$       \\ \hline
        including parameter analysis & $0.95 \pm 0.05$ & $0.09 \pm 0.11$ & $0.93 \pm 0.07$ & $1.00$       \\ \hline
    \end{tabularx}
\end{table}

Our results show that the second scenario improves the overall detection,
with TPR and $F_{1}$ raising from $0.91$ and $0.82$ to $0.95$ and $0.93$
respectively and FPR lowering from $0.31$ to $0.09$, even though both
scenarios have groups that achieve a perfect score.
These results demonstrate the usefulness of including the analysis of
parameter values.

Comparing our results with related works that use the same data sets that
we employ, we find that in \cite{parhizkar2015oc} a TPR of $0.96$ and a
FPR of $0.03$ is reported for the ensemble of \textit{One-Class} SVMs.
Two popular \textit{misuse-based} WAFs,
ModSecurity\footnote{\url{www.modsecurity.org}}
and PHPIDS\footnote{\small \url{https://github.com/PHPIDS/PHPIDS}},
were used with default rules on the first data set, CSIC 2010, obtaining
a TPR of only $0.55$ and $0.29$ respectively \cite{gimenez2015paper},
significantly lower than the results we achieved with our WAF.


\subsection{Response time analysis}

Our second test aimed to quantify the effects our WAF has on the response
time of the web applications it protects. To that end, we set up a simple
application and measured the response time in three different scenarios;
in one the requests went directly to the application, in the second the
traffic was routed through our WAF but with detection disabled, and in
the third scenario with enabled detection.
The second and third scenarios show an increase of 2 and 4 ms respectively
when compared to the scenario without the WAF. This delay is only a small
increase compared to the overall roundtrip time of HTTP traffic, so our WAF
should not have noticeable effects on the response time.


\subsection{Training time analysis}

In our third test, we analyzed how the training time of our WAF relates
to the amount of requests used. Since groups may have different durations
because of an unequal number of features, the highest numbers give an
upper bound.
We observed that the time per request stays close to 2 ms in our test
setup with 10,000 requests. Our numbers show that the training time has
an almost linear relationship to the amount of training data.


\section{Conclusions}
\label{chap:conclusions}

The WAF we present in this article uses the \textit{One-Class} SVM
classifier to tackle the task of detecting anomalous HTTP requests in
order to protect web applications from possible attacks.
Following and extending the ideas obtained from other authors, we built
feature extraction methods that take advantage of the structure of HTTP
requests, specifically the values of individual parameters, to represent
these requests with vectors which contain more useful information.
Our tests show a significant improvement in the detection results when
including the analysis of parameter values.
Furthermore, our implementation shows that it is fast enough to be used
as a WAF, even though the minimization of the processing time was not
our primary goal and further optimizations could be made.

One contribution of our paper is the adaptation and extension of the
parameter value analysis presented in \cite{kruegel2003anomaly}. The
anomaly models employed by the cited authors do not produce numeric vectors
for each request, and so we adapted them to make feature extraction methods
that are useful for Machine Learning tools, in our case specifically the
\textit{One-Class} SVM.
As another contribution, we leave a link in Section \ref{chap:proposal}
to the online repository that contains the code of our implementation,
which includes the WAF and the tests mentioned in this paper, so that
other authors can reproduce our results and have a starting point for
further research.

Future works could look into finding additional features to detect anomalous
requests. Another research area is other classification tools to be used instead
of the \textit{One-Class} SVM to tackle the OCC task.
Additionally, our work lacks automatic selection of the
values for $\nu$ and $\gamma$ of the classifier and further inquiries
can be made in that direction.
